{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prosta sieć przewidująca typ kwiatów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tym notebooku stworzymy kilka prostych sieci neuronowych za pomocą biblioteki keras do wykrywania typu irysa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T20:42:04.800022Z",
     "start_time": "2019-04-05T20:42:03.303776Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za pomocą pakietu pandas Załadujmy dane ze zbioru IRIS dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:21:52.530842Z",
     "start_time": "2019-04-05T18:21:52.523840Z"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeanalizujmy zestaw danych:\n",
    "* informacjami o zmiennych\n",
    "* statystykami opisowymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:21:54.331208Z",
     "start_time": "2019-04-05T18:21:54.325218Z"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:21:55.982881Z",
     "start_time": "2019-04-05T18:21:55.956875Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak rozkładają się różne klasy kwiatów w tym zbiorze?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:21:57.633996Z",
     "start_time": "2019-04-05T18:21:57.628995Z"
    }
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby wygodnie korzystać z modeli uczenia maszynowego w pythonie podziel kolumny ramki na predyktory X i zmienną niezależną :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:04.314199Z",
     "start_time": "2019-04-05T18:22:04.310195Z"
    }
   },
   "outputs": [],
   "source": [
    "X = iris.drop('y', axis=1)\n",
    "y = iris['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak wygląda X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:05.734521Z",
     "start_time": "2019-04-05T18:22:05.726528Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak wygląda y?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:09.242411Z",
     "start_time": "2019-04-05T18:22:09.238411Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, etykiety do naszego zbioru są wektorem z przypisanymi numerami kategorii. Aby zamienić taką zmienną kategorialną na format odpowiedni dla kerasa, należy dokonać procesu kodowania 'one-hot' encoding. Nasze etykiety będą teraz reprezentowane przez binarną macierz, w której każda kolumna będzie odpowiadała jednej kategorii. Możemy to zrobić na kilka sposobów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:16.431089Z",
     "start_time": "2019-04-05T18:22:16.423096Z"
    }
   },
   "outputs": [],
   "source": [
    "# sposób1 - na bazie macierzy jednostkowej\n",
    "y_onehot = np.eye(3)[y.astype('int')]\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:20.999001Z",
     "start_time": "2019-04-05T18:22:20.991009Z"
    }
   },
   "outputs": [],
   "source": [
    "# sposób2 - z indeksowaniem\n",
    "y_onehot = np.zeros((150,3))\n",
    "y_onehot[np.arange(150), y.astype('int')] = 1\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:24.487694Z",
     "start_time": "2019-04-05T18:22:24.480683Z"
    }
   },
   "outputs": [],
   "source": [
    "# sposób3 - z pomocą Kerasa\n",
    "from keras.utils import np_utils\n",
    "y_onehot = np_utils.to_categorical(y, 3)\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podzielmy teraz losowo nasz zbiór na uczący i testowy za pomocą wbudowanych funkcji sklearna. Niech zbiór testowy zawiera 20% całego zbioru obserwacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:30.112400Z",
     "start_time": "2019-04-05T18:22:29.897351Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "print('X_train shape:{}'.format(X_train.shape))\n",
    "print('X_test shape:{}'.format(X_test.shape))\n",
    "\n",
    "print('y_train shape:{}'.format(y_train.shape))\n",
    "print('y_test shape:{}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimportujmy Sequential będące modelem sieci neuronowej w Kerasie, oraz Dense -  podstawową warstwę ukrytą"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:42.581755Z",
     "start_time": "2019-04-05T18:22:42.577763Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaininicjujmy obiekt klasy Sequential. Następnie za pomocą metody `.add` będziemy dodawać kolejne warstwy ukryte i końcową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:46.184616Z",
     "start_time": "2019-04-05T18:22:46.169621Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodajmy do naszej sieci warstwę typu Dense. W pierwszej warstwie należy wyspecyfikować `input_dim` liczbę zmiennych będących predyktorami. Ponadto należy podać liczbę neuronów `units`, oraz funkcję aktywacji dla tej warstwy `activation`. Jako funkcję aktywacji podajmy *Rectified Linear Unit* - `relu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:48.899074Z",
     "start_time": "2019-04-05T18:22:48.883069Z"
    }
   },
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(units=50, input_dim=4, activation='relu')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodajmy teraz warstwę składającą się z 50 neuronów, z taką samą funkcją aktywacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:51.152268Z",
     "start_time": "2019-04-05T18:22:51.138265Z"
    }
   },
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(units=100, activation='relu')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na sam koniec dodajmy warstwę końcową z trzema neuronami, w której każdy neuron będzie przedstawiał prawdopobieństwo wystąpienia danej klasy. Z jakiej funkcji aktywacji skorzystamy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:54.304120Z",
     "start_time": "2019-04-05T18:22:54.291118Z"
    }
   },
   "outputs": [],
   "source": [
    "model.add(\n",
    "    Dense(units=3,...?)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy teraz sieć neuronową składającą się z dwóch warstw ukrytych i jednej wyjściowej. Sprawdźmy sobie podsumowanie dla tego modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:22:57.110989Z",
     "start_time": "2019-04-05T18:22:57.107987Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To samo możemy zrobić w formie graficznej. Pamiętaj o zainstalowaniu pydot i graphviz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:10:13.184620Z",
     "start_time": "2019-04-05T19:10:13.080595Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='LR'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:23:05.392209Z",
     "start_time": "2019-04-05T18:23:05.388208Z"
    }
   },
   "outputs": [],
   "source": [
    "# przypadku gdy nie mamy zainstalowanego, to instalujemy pakiet graphviz, i zmieniamy zmienną PATH w systemie.\n",
    "# Możemy zmienić ją także z poziomu pythona\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy otworzyć tak stworzony obraz na dysku bądź z poziomu jupyter notebooka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:23:13.865507Z",
     "start_time": "2019-04-05T18:23:13.861506Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po zdefiniowaniu architektury sieci, za pomocą `.compile` należy skonfigurować taki model do procesu uczenia. Najważniejsze parametry, jakie trzeba zdefiniować to:\n",
    "* `loss` - funkcja straty\n",
    "* `optimizier` - rodzaj optymalizatora\n",
    "* `metrics` - lista metryk do ewaluacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:23:22.292312Z",
     "start_time": "2019-04-05T18:23:22.262305Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    "    loss='categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optymalizator może być stringiem z zakresu dostępnych w bilbiotece. Może być też obiektem z keras.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:25:31.498939Z",
     "start_time": "2019-04-05T18:25:31.466931Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "opt = optimizers.Adam(lr=0.001)\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'],\n",
    "    loss='categorical_crossentropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po skonfigurowaniu modelu możemy przejść do trenowania za pomocą metody `.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:25:40.783755Z",
     "start_time": "2019-04-05T18:25:38.971467Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=150\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak nasza sieć działa na zbiorze, który nie brał udziału w procesie uczenia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:25:47.370593Z",
     "start_time": "2019-04-05T18:25:47.315580Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli chcielibyśmy dokonać predykcji dla konkretnej obserwacji, korzystamy z funkcji `.predict`. Metoda przyjmuje macierz 2D o kształcie (liczba obserwacji, liczba cech):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:25:59.850705Z",
     "start_time": "2019-04-05T18:25:59.845704Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.iloc[0].shape)\n",
    "print(np.expand_dims(X_train.iloc[0], axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:26:05.569868Z",
     "start_time": "2019-04-05T18:26:05.541871Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "predictions = model.predict(...)\n",
    "print(predictions)\n",
    "# jak programistycznie wyciągnąć numer klasy z najwyższym prawdopobieństwem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:26:11.618872Z",
     "start_time": "2019-04-05T18:26:11.494843Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.bar(x=[1,2,3], height=np.squeeze(predictions))\n",
    "plt.title('Prawdopobieństwo wystąpienia danej klasy dla danego przypadku \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizując obiekt `history` możemy zobaczyć jak wyglądała skuteczność treningowa podczas procesu uczenia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:26:18.407532Z",
     "start_time": "2019-04-05T18:26:18.303507Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('Skuteczność na danych treningowych')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdybyśmy chcieli zobaczyć jak w procesie uczenia sieć dopasowała wagi, tak wygląda to dla pierwszej warstwy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:31:11.179385Z",
     "start_time": "2019-04-05T18:31:11.171380Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć przewidująca typ kwiatów - praca własna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie do samodzielnego rozwiązania\n",
    "\n",
    "Stwórz sieć neuronową mającą 4 warstwy:\n",
    "* Warstwa 50 neuronów, funkcja aktywacji `tanh`\n",
    "* Dwie warstwy po 100 neuronów z funkcją aktywacji `tanh`\n",
    "* Warstwa z trzema neuronami, z funkcją aktywacji `softmax`\n",
    "\n",
    "Do skonfigurowania `.compile`, wykorzystaj optymalizator `adam` z learning_rate na poziomie 0.0001, funkcja straty to `categorical_crossentropy`. \n",
    "\n",
    "do metody fit dodaj argument `validation_data=(X_test, y_test)` - pozwoli on na jednoczesną ewaluację modelu na danych walidacyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:31:40.475548Z",
     "start_time": "2019-04-05T18:31:38.607279Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stwórz wykres przedstawiający skuteczność treningową i testową w zależności od numeru epoki.\n",
    "Analizując obiekt historii do skuteczności treninowej dobierzesz się `history.history['acc']`, natomiast do skuteczności testowej `history.history['val_acc']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:32:43.559459Z",
     "start_time": "2019-04-05T18:32:43.429351Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sieć przewidująca wynik meczu piłkarskiego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie do samodzielnego wykonania\n",
    "Poniżej wczytasz dane dotyczące historycznych spotkań piłkarskich w pierwszej lidze hiszpańskiej. Dla ułatwienia proces oczyszczania danych i feature engineeringu został już przeprowadzony.\n",
    "W pliku `liga_hiszpanska.csv` znajdziesz wszystkie mecze dla sezonów od 2005 do 2016. Twoim zadaniem jest:\n",
    "* Wczytaj dane\n",
    "* Przeanalizuj zbiór (`.info, .describe, .head`)\n",
    "* Zakoduj zmienną ['Outcome'] do postaci 'one-hot encoding'. Hint: przyjrzyj się funkcji `pd.get_dummies()`. Wynik zapisz do zmiennej `one_hot`\n",
    "* Stwórz zbiór uczący X_train- to zbiór, w którym `Season` jest starszy niż 2015\n",
    "* Stwórz zbiór validacyjny X_valid - to zbiór w którym `Season` to 2015\n",
    "* Stwórz zbiór testowy X_test - to zbiór, w którym `Season` to 2016\n",
    "Zmienne będące predyktorami znajdziesz w liście o nazwie `features` w komórce poniżej\n",
    "\n",
    "Nie zapomnij dla każdego z tych zbiorów stworzyć odpowiadających im macierzy etykiet y_train, y_test, y_valid\n",
    "\n",
    "Przykładowe stworzenie zbioru treningowego \n",
    "\n",
    "`X_train = dane.loc[dane['Season'] <= 2014, features]`\n",
    "\n",
    "`y_train = one_hot.loc[dane['Season'] <= 2014, ].values`\n",
    "\n",
    "* Za pomocą `StandardScaler` z pakietu `scikit-learn` dokonaj standaryzacji na zbiorze uczącym . Ten sam obiekt klasy StandardScaler wykorzystaj do zestandaryzowania X_test i X_valid\n",
    "\n",
    "* Następnie stwórz model sieci neuronowej, architekturę wybierz dowolnie. Pamiętaj, że w przypadku przeuczenia modelu, możesz spróbować dodać regularyzację typu Dropout po każdej warstwie `Dense`, w taki sposób: `model.add(Dropout(rate=?))`\n",
    "* Po zdefiniowaniu architektury sieci, uruchom proces trenowania.\n",
    "\n",
    "* Wykreśl przebieg skuteczności uczącej i walidacyjnej w czasie\n",
    "* Na samym końcu dokonaj ewaluacji modelu na danych ze zbioru testowego - takiego, który wcześniej nie brał udziału w procesie uczenia\n",
    "* Sprawdź jak Twoja sieć neuronowa działa w porównaniu z klasyfikatorem kNN, oraz z klasyfikatorem naiwnym - tj obstaw, że we wszystkich przypadkach wygrają gospodarcze meczu. hint: żeby z 'one-hot encoding' przejść do numerów klas w jednym wektorze wykorzystaj `y_test.argmax(axis=-1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T20:31:32.345491Z",
     "start_time": "2019-04-05T20:31:32.281486Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwolucyjna sieć neuronowa - MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tym razem wytrenujemy sieć konwolucyjną do rozpoznawania ręcznie zapisanych cyfr z obrazów - popularny zbiór MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pobierzmy odpowiednie dane z wbudowanej funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:14.441358Z",
     "start_time": "2019-04-05T18:54:14.219317Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ile mamy obserwacji?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:15.416587Z",
     "start_time": "2019-04-05T18:54:15.412587Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Narysujmy pierwszą wybraną obserwację ze zbioru uczącego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:17.480580Z",
     "start_time": "2019-04-05T18:54:17.475579Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:21.440896Z",
     "start_time": "2019-04-05T18:54:21.331870Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby dostosować format danych do przetwarzania przez Kerasa, wymiary naszego zbioru muszą mieć następującą postać:\n",
    "`(liczba obserwacji, liczba kanałów obrazu, wysokość, szerokość)`. Jest to tzw format 'channels_first'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:33.248145Z",
     "start_time": "2019-04-05T18:54:33.244145Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test= X_test.reshape(X_test.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wymiary po rozszerzeniu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:34.704520Z",
     "start_time": "2019-04-05T18:54:34.701528Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizujemy dane do zakresu [0,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:44.970599Z",
     "start_time": "2019-04-05T18:54:44.854564Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tak jak w poprzednim przypadku musimy zastosować 'one-hot encoding' dla naszych etykiet. Wykorzystaj np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:47.882657Z",
     "start_time": "2019-04-05T18:54:47.878655Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = ...\n",
    "Y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załadujmy odpowiednie rodzaje warstw do przetwarzania obrazów:\n",
    "* `Flatten` jest warstwą, która spłaszcza dane\n",
    "* `Convolution2D` jest warstwą konwolucyjną. Pierwszy parametr to liczba filtrów w warstwie, a drugi to krotka (x,x) oznaczająca wielkość filtra. W pierwszej warstwie zdefiniujemy też format danych - będzie to `channels_first`, i odpowiadająca formatowi (1,28,28). W przypadku wariantu `channel_last` byłoby to (28, 28, 1)\n",
    "* `MaxPooling2D` - to warstwa poolingu, która dla zadanej wielkości okna `pool_size` wybiera wartość największą, dzięki czemu zmniejsza wymiar danych\n",
    "* `Dropout` to warstwa regularyzacyjna. Przyjmuje argument `rate`, który oznacza jaka frakcja neuronów jest zamrażana w każdym kolejnym przejściu danych przez sieć (*forward pass*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:53.914093Z",
     "start_time": "2019-04-05T18:54:53.910092Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:54:57.204805Z",
     "start_time": "2019-04-05T18:54:57.062768Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ile parametrów będziemy 'uczyć'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:55:27.693196Z",
     "start_time": "2019-04-05T18:55:27.689205Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:57:19.588153Z",
     "start_time": "2019-04-05T18:56:12.294964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train, \n",
    "    batch_size=32,\n",
    "    nb_epoch=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po wytrenowaniu sieci, możemy zwizualizować wyuczone filtry. Najpierw pobierzmy wszystkie wartości wag z pierwszej warstwy konwolucyjnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T15:31:46.545665Z",
     "start_time": "2019-04-05T15:31:46.540673Z"
    }
   },
   "outputs": [],
   "source": [
    "layer = model.get_layer(... - podaj nazwę pierwszej warstwy konwolucyjnej)\n",
    "weights = layer.get_weights()[0]\n",
    "biases = layer.get_weights()[1]\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Usuńmy zbędny wymiar za pomocą funkcji `np.squeeze`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T15:32:01.833340Z",
     "start_time": "2019-04-05T15:32:01.830331Z"
    }
   },
   "outputs": [],
   "source": [
    "weights_reshaped = np.squeeze(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I narysujmy filtry wyuczone przez sieć"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T15:33:35.142521Z",
     "start_time": "2019-04-05T15:33:33.576633Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "for i in range(32):\n",
    "    plt.subplot(6, 6, 1 + i)\n",
    "    plt.imshow(weights_reshaped[:, :, i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja - CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zadanie do samodzielnego rozwiązania\n",
    "Zapoznaj się ze zbiorem danych CIFAR-10 https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "* Załaduj dane analogicznie jak w przypadku zbioru mnist `keras.datasets.cifar10`. Przeanalizuj kształt otrzymanych danych. Jest to channels_first, czy channels_last?\n",
    "* Za pomocą kodu dostępnego niżej zwizualizuj pierwszych 25 obserwacji w zbiorze\n",
    "* Przekształć zmienną prognozowaną za pomocą 'one-hot encoding'\n",
    "* Zmień typ danych x_train, i x_test na float32\n",
    "* Znormalizuj x_train i x_test do wartości z zakrsu 0-1 (podziel przez 255)\n",
    "* Stwórz model sieci neuronowej, używając architektury zawartej w dołączonym pliku `cifar_architecture.png`\n",
    "* Skonfiguruj model używając dowolnie wybranego optymalizatora\n",
    "* Zacznij proces trenowania, przyjmując `batch_size=64`. Liczbę epok ustaw na 5 `epochs=15`. Pamiętaj o dodaniu zbioru walidacyjnego jako parametr metody `.fit`. Skorzystaj z dostępnego już fragmentu kodu - zapisuje on na dysku wagi, jeśli skuteczność walidacyjna się zwiększyła\n",
    "* Pójdź na kawę. Jeśli proces będzie się przedłużał, to wyłącz działanie komórki, i zmniejsz dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:19:20.730478Z",
     "start_time": "2019-04-05T19:19:20.485995Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:57:49.699151Z",
     "start_time": "2019-04-05T18:57:49.696150Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:59:33.190432Z",
     "start_time": "2019-04-05T18:59:33.185431Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:16:27.880854Z",
     "start_time": "2019-04-05T19:16:27.292413Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['Airplane','Automobile','Bird', 'Cat','Deer','Dog','Frog','Horse','Ship','Truck']\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i,])\n",
    "    plt.xlabel(class_names[y_train[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:19:23.836322Z",
     "start_time": "2019-04-05T19:19:23.829320Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:19:25.557098Z",
     "start_time": "2019-04-05T19:19:25.165992Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:54:00.885461Z",
     "start_time": "2019-04-05T19:54:00.844452Z"
    }
   },
   "outputs": [],
   "source": [
    "# w razie potrzeby zmniejszenia zbioru danych:\n",
    "mask = np.random.choice(50000, 6000, replace=False)\n",
    "print(x_train[mask].shape)\n",
    "print(y_train[mask].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:19:26.699585Z",
     "start_time": "2019-04-05T19:19:26.629572Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:19:28.910785Z",
     "start_time": "2019-04-05T19:19:28.877790Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:20:35.511292Z",
     "start_time": "2019-04-05T19:20:35.509293Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:33:57.457858Z",
     "start_time": "2019-04-05T19:20:49.207590Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'best_weigths.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max'\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            batch_size=64,\n",
    "            epochs=15,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True,\n",
    "         callbacks=[checkpoint])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
