{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T17:22:24.231977Z",
     "start_time": "2019-04-03T17:22:23.458468Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wstępna analiza danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Załadujmy dane z zestawu IRIS i umieśćmy je w ramce danych. IRIS to najpopularniejszy zbiór danych do nauki analizy danych i przedstawia 150 egzemplarzy kwiatów należących do trzech gatunków."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T17:22:25.385450Z",
     "start_time": "2019-04-03T17:22:25.379448Z"
    }
   },
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak wyglądają te dane - kilka pierwszych obserwacji?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T14:16:25.364129Z",
     "start_time": "2019-04-03T14:16:25.346125Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T14:01:30.483978Z",
     "start_time": "2019-04-02T14:01:30.475986Z"
    }
   },
   "source": [
    "Ile jest zmiennych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T14:16:27.554683Z",
     "start_time": "2019-04-03T14:16:27.544693Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak wyglądają podstawowe statystyki opisowe dla zmiennych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T14:16:28.895729Z",
     "start_time": "2019-04-03T14:16:28.873725Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T14:30:48.801346Z",
     "start_time": "2019-04-02T14:30:48.798346Z"
    }
   },
   "source": [
    "Przedstaw histogramy każdej ze zmiennej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T17:21:51.865207Z",
     "start_time": "2019-04-03T17:21:51.688176Z"
    }
   },
   "outputs": [],
   "source": [
    "iris['sepal length (cm)'].hist(bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T17:21:54.029643Z",
     "start_time": "2019-04-03T17:21:53.848568Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_1 = iris[iris['y']==0]['sepal length (cm)']\n",
    "class_2 = iris[iris['y']==1]['sepal length (cm)']\n",
    "class_3 = iris[iris['y']==2]['sepal length (cm)']\n",
    "plt.hist(class_1, alpha=0.5, label='0', color='b')\n",
    "plt.hist(class_2, alpha=0.5, label='0', color='r')\n",
    "plt.hist(class_3, alpha=0.5, label='0', color='g')\n",
    "plt.legend(loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przedstaw graficznie zależność (scatterplot) między długością (x), a szerokością (y) płatka (*petal*). Kolorem oznacz gatunek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T17:21:58.978112Z",
     "start_time": "2019-04-03T17:21:58.833077Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(iris['petal length (cm)'], iris['petal width (cm)'], c=iris['y'])\n",
    "plt.title('Zależność między długością a szerokością płatka \\n', size=16)\n",
    "plt.xlabel('Szerokość płatka')\n",
    "plt.ylabel('Długość płatka')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przedstaw graficznie zależność (scatterplot) między długością (x), a szerokością (y) kielicha (*sepal*). Kolorem oznacz gatunek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak wygląda macierz korelacji dla tego zbioru? (pamiętaj o wyłączeniu zmiennej y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:23:37.893952Z",
     "start_time": "2019-04-03T15:23:37.884950Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = iris.drop('y', axis=1).corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przedstaw graficznie macierz korelacji (sposób I - matplotlib):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:23:43.589396Z",
     "start_time": "2019-04-03T15:23:43.405314Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.matshow(corr, vmin=-1, vmax=1, cmap='bwr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Więcej o stylowaniu heatmap w matplotlibie : https://matplotlib.org/gallery/images_contours_and_fields/image_annotated_heatmap.html\n",
    "* Inne zestawy kolorystyczne:\n",
    "https://matplotlib.org/examples/color/colormaps_reference.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Sposób II - od pandasa w wersji >0.23):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:23:45.766382Z",
     "start_time": "2019-04-03T15:23:45.485407Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sposób III - seaborn plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:23:47.347173Z",
     "start_time": "2019-04-03T15:23:47.173108Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza głównych składowych - od podstaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W tej części od podstaw dokonamy redukcji wymiarowości przez metodę głównych składowych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyrzućmy z ramki zmienną 'y' i zapiszmy ją osobno- do analizy PCA nie jest nam ona potrzebna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:30:54.337949Z",
     "start_time": "2019-04-03T16:30:54.334949Z"
    }
   },
   "outputs": [],
   "source": [
    "y = iris.pop('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mamy teraz dwie równoważne możliwości:\n",
    "* dokonujemy dekompozycji macierzy korelacji\n",
    "* dokonujemy dekompozycji macierzy kowariancji na ustandaryzowanych danych\n",
    "\n",
    "Dla dociekliwych dyskusja o tych dwóch podejściach: https://stats.stackexchange.com/a/78\n",
    "\n",
    "<font size=\"1\">Należy pamiętać o transpozycji jeśli jest wymagana. Funkcje np.corrcoef, i np.cov przyjmują macierze, w których wiersze to zmienne</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:30:56.628722Z",
     "start_time": "2019-04-03T16:30:56.622721Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# macierz korelacji\n",
    "corr_matrix = np.corrcoef(iris.T)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:30:58.263755Z",
     "start_time": "2019-04-03T16:30:58.254753Z"
    }
   },
   "outputs": [],
   "source": [
    "srednie = np.mean(iris) # średnie wartości zmiennych\n",
    "odchylenia = np.std(iris, ddof=1) # odchylenia standardowe zmiennych\n",
    "\n",
    "iris_standardized = (iris - srednie) / odchylenia # \n",
    "np.cov(iris_standardized.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonaj dekompozycji macierzy korelacji (bądź kowariancji) za pomocą funkcji: <br>\n",
    "`numpy.linalg.eig(a)` <br>\n",
    "Zwraca: <br>\n",
    "`w The eigenvalues, each repeated according to its multiplicity. ` <br>\n",
    "`v The normalized (unit “length”) eigenvectors, such that the column v[:,i] is the eigenvector corresponding to the eigenvalue w[i]`\n",
    "\n",
    "<font size=\"1\">https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.eig.html</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:31:00.174181Z",
     "start_time": "2019-04-03T16:31:00.167180Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dekompozycja = np.linalg.eig(corr_matrix)\n",
    "wartosci_wlasne = dekompozycja[0]\n",
    "wektory_wlasne = dekompozycja[1]\n",
    "print('Wartości własne: {}'.format(wartosci_wlasne))\n",
    "print('Wektory własne: {}'.format(wektory_wlasne))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procent wyjaśnianej wariancji przez poszczególne składowe możemy obliczyć jako wartość własną odpowiadającą danej składowej podzieloną przez sumę wszystkich wartości własnych.\n",
    "\n",
    "<font size=1>Należy w razie potrzeby uporządkować wektory własne według malejących wartości własnych</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:31:02.442499Z",
     "start_time": "2019-04-03T16:31:02.438499Z"
    }
   },
   "outputs": [],
   "source": [
    "wyjasniane_war = wartosci_wlasne / np.sum(wartosci_wlasne)\n",
    "print(wyjasniane_war)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaprezentuj udziały wyjaśnianych wariancji na wykresie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:31:04.945922Z",
     "start_time": "2019-04-03T16:31:04.839752Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([1,2,3,4], wyjasniane_war, ls='--', marker='.', ms=10)\n",
    "plt.xticks(np.arange(1,5, 1.0)) # etykiety osi poziomej w przyjaznej formie\n",
    "plt.ylabel('Wyjaśniana wariancja')\n",
    "plt.xlabel('Główna składowa')\n",
    "plt.title('Numer głównej składowej a \\n wyjaśniana wariancja \\n', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaprezentuj skumulowane udziały wyjasnianych wariancji na wykresie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:31:06.998811Z",
     "start_time": "2019-04-03T16:31:06.895799Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:31:08.974272Z",
     "start_time": "2019-04-03T16:31:08.969280Z"
    }
   },
   "outputs": [],
   "source": [
    "wektory_wlasne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:33:06.297147Z",
     "start_time": "2019-04-03T16:33:06.292155Z"
    }
   },
   "source": [
    "Obliczmy macierz ładunków:\n",
    "$ Ładunki = Wektory własne * \\sqrt{wartości  własne}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:37:11.919740Z",
     "start_time": "2019-04-03T16:37:11.916739Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "macierz_ladunkow = wektory_wlasne * np.sqrt(wartosci_wlasne)\n",
    "print(macierz_ladunkow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zamieńmy ją na trochę przyjaźniejszą dla analityka wersję"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:45:38.328749Z",
     "start_time": "2019-04-03T16:45:38.318748Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ramka_ladunkow = pd.DataFrame(\n",
    "    macierz_ladunkow, columns=['Skladowa{}'.format(i) for i in range(1,5)],\n",
    "    index=iris.columns\n",
    ")\n",
    "ramka_ladunkow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:36:08.682953Z",
     "start_time": "2019-04-03T16:36:08.678952Z"
    }
   },
   "source": [
    "Zinterpretujmy macierz ładunków:\n",
    "* Korelacja między długością płatka a Składową1 jest bardzo wysoka (0.99)\n",
    "* W przypadku składowej2, oryginalną zmienną, która była najbardziej skorelowana była długość kielicha\n",
    "* Składowe 3 i 4 nie są zbytnio skorelowane z oryginalnymi zmiennymi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na bazie wykresów można przyjąć, że dwie główne składowe wyjaśnianiją wystarczająco dużo wariancji. Zredukujemy liczbę wymiarów do dwóch. Na początek stwórzmy macierz przekształcenia $W$ - kolumny są w niej więc dwoma pierwszymi wektorami własnymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:31:10.403721Z",
     "start_time": "2019-04-03T16:31:10.400721Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "macierz_przeksztalcen = wektory_wlasne[:,0:2]\n",
    "print(macierz_przeksztalcen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:06:47.004051Z",
     "start_time": "2019-04-02T18:06:47.001050Z"
    }
   },
   "source": [
    "Obserwacje przekształcone do dwóch wymiarów uzyskamy mnożąc macierz zawierającą zestandaryzowane dane w oryginalnej przestrzeni przez macierz przekształceń.\n",
    "\\begin{equation*}\n",
    "Y = X W\n",
    "\\end{equation*}\n",
    "Pomocna będzie funkcja `np.dot`. Pamiętaj, że w przypadku macierzy kolejność mnożenia ma znaczenie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:31:13.735903Z",
     "start_time": "2019-04-03T16:31:13.728911Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zróbmy z tego nową ramkę danych *new_data* o kolumnach:\n",
    "* Skladowa1\n",
    "* Skladowa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:34:43.413088Z",
     "start_time": "2019-04-02T18:34:43.409087Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(\n",
    "    np.dot(iris_standardized, macierz_przeksztalcen),\n",
    "    columns=['Skladowa1', 'Skladowa2']\n",
    ")\n",
    "\n",
    "# hint - dla większej liczby składowych nazwy kolumn można wygenerować za pomocą mechanizmu 'list comprehension':\n",
    "#['Skladowa{}'.format(i) for i in range(1,3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:28:32.056812Z",
     "start_time": "2019-04-02T18:28:32.043809Z"
    }
   },
   "source": [
    "Przedstaw nowe dane w przestrzeni dwuwymiarowej na wykresie punktowym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:01:34.214754Z",
     "start_time": "2019-04-02T19:01:34.083297Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza głównych składowych - sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importujemy odpowiednią klasę z modułu $decomposition$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:53:42.496705Z",
     "start_time": "2019-04-03T15:53:42.007742Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiujemy model (musimy podać liczbę głównych składowych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:51:25.394363Z",
     "start_time": "2019-04-02T18:51:25.390362Z"
    }
   },
   "outputs": [],
   "source": [
    "model_pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przekształcamy na danych zestandaryzowanych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:51:27.637627Z",
     "start_time": "2019-04-02T18:51:27.630624Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data_sklearn = model_pca.fit_transform(iris_standardized)\n",
    "print(new_data_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:40:19.670354Z",
     "start_time": "2019-04-02T18:40:19.667352Z"
    }
   },
   "source": [
    "Wartości własne możemy uzyskać z właściwości `.explained_variance_`, natomiast % wyjaśnianej wariancji z właściwości `.explained_variance_ratio_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:51:30.449759Z",
     "start_time": "2019-04-02T18:51:30.446758Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:51:32.001666Z",
     "start_time": "2019-04-02T18:51:31.998664Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... oraz wektory własne za pomocą `.components_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:51:32.770947Z",
     "start_time": "2019-04-02T18:51:32.766947Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T18:52:50.179772Z",
     "start_time": "2019-04-02T18:52:50.175772Z"
    }
   },
   "source": [
    "<font size=2>Czasami wyniki dla dekompozycji macierzy kowariancji i mechanizmu sklearna mogą się różnić w kwestii znaku przed wektorami własnymi - sklearn pod spodem używa mechanizmu *Singular Value Decomposition*. Dla analizy nie ma to istotnego znaczenia. Dla dociekliwych: https://stackoverflow.com/a/44847053</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaprezentujmy teraz obserwacje w przestrzeni dwóch pierwszych składowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:01:39.597599Z",
     "start_time": "2019-04-02T19:01:39.467037Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza głównych składowych - digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spróbujemy teraz za pomocą analizy głównych składowych zredukować liczbę zmiennych potrzebnych do opisania danych w postaci obrazów. Wykorzystamy zbiór danych digits - przedstawia on ~1800 cyfr, a każda z nich jest reprezentowana przez 64 wartości (obraz 8x8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:10:43.218563Z",
     "start_time": "2019-04-02T19:10:43.130461Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wielkość danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:10:57.158701Z",
     "start_time": "2019-04-02T19:10:57.155700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby w szybki sposób zobaczyć ile różnych cyfr przedstawia zbiór, możemy wektor z informacją 'target' przekształcić do pandasowej Series, i wywołać value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:14:07.948650Z",
     "start_time": "2019-04-02T19:14:07.943649Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W numpy wyglądałoby to tak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:16:02.574768Z",
     "start_time": "2019-04-02T19:16:02.570779Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(digits['target'], return_counts=True)\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy wyplotować dowolne cyfry ze zbioru:\n",
    "<font size=1>Kod do wygenerowania wykresu:\n",
    "https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:21:55.734959Z",
     "start_time": "2019-04-02T19:21:55.469908Z"
    }
   },
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r)\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pamiętajmy o standaryzacji danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:51:17.018145Z",
     "start_time": "2019-04-02T19:51:17.015144Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:29:14.174609Z",
     "start_time": "2019-04-02T19:29:14.162615Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "digits_pca = PCA(n_components=2)\n",
    "dwa_wymiary = digits_pca.fit_transform(digits['data'])\n",
    "print(dwa_wymiary.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ile % wariancji wyjaśniają dwa pierwsze wymiary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:29:41.544480Z",
     "start_time": "2019-04-02T19:29:41.540479Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W takim przypadku możemy zwizualizować sobie wektor odpowiadający pierwszej głównej składowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:48:04.405667Z",
     "start_time": "2019-04-02T19:48:04.291640Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(digits_pca.components_[0].reshape(8,8), cmap=plt.cm.gray_r)\n",
    "plt.title('Wektor odpowiadający pierwszej głównej składowej', size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T19:33:05.925019Z",
     "start_time": "2019-04-02T19:33:05.625951Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(dwa_wymiary[:,0], dwa_wymiary[:,1], c=digits['target'], cmap='Paired')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonaj rzutowania oryginalnej przestrzeni danych Digits na przestrzeń trójwymiarową. Ile % wariancji wyjaśniają trzy pierwsze główne składowe? Jak zbiór danych wygląda w 3D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonaj rzutowania oryginalnej przestrzeni danych Digits na wszystkie 64 wymiary - wykreśl skumulowany odsetek wyjaśnianej wariancji? Ile głównych składowych byś wybrał?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA vs T-SNE - swissroll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:52:53.630687Z",
     "start_time": "2019-04-03T15:52:53.626686Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_swiss_roll\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wygenerujmy losowy zbiór danych za pomocą funkcju make_swiss_roll, i zwizualizujmy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:01:07.787205Z",
     "start_time": "2019-04-03T16:01:07.612164Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fake_data, _= make_swiss_roll(1000)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.view_init(10, 70)\n",
    "ax.scatter(fake_data[:,0], fake_data[:,1], fake_data[:,2], c=_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokonaj dekompozycji powyższego zbioru na 2 główne składowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:54:20.615835Z",
     "start_time": "2019-04-03T15:54:20.611834Z"
    }
   },
   "outputs": [],
   "source": [
    "swiss_pca =\n",
    "new_data ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaki procent wariancji wyjaśniają dwie główne składowe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:55:06.364217Z",
     "start_time": "2019-04-03T15:55:06.360225Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwizualizuj dwie pierwsze główne składowe. Jako kolor ustaw parametr _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:01:19.610106Z",
     "start_time": "2019-04-03T16:01:19.438074Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaimportujmy teraz klasę TSNE do stworzenia modelu t-Stochasting Neighbour Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T15:56:53.840872Z",
     "start_time": "2019-04-03T15:56:53.691747Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyj modelu TSNE do redukcji wymiarów do 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:05:50.445492Z",
     "start_time": "2019-04-03T16:05:46.880740Z"
    }
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=10)\n",
    "tsne_results = tsne.fit_transform(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:03:54.816245Z",
     "start_time": "2019-04-03T16:03:54.813256Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zwizualizuj zbiór swiss_roll zredukowany za pomocą TSNE do dwóch wymiarów (pamiętaj o kolorze):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T16:05:53.203821Z",
     "start_time": "2019-04-03T16:05:53.032794Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeanalizuj redukcję wymiarów przy użyciu różnych wartości parametrów *perplexity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Praca własna - jakość życia w Polsce w 2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W pliku csv załączonym do repozytoriów znajdziesz zbiór danych dotyczący jakości życia w Polsce w podziale na powiaty\n",
    "Zmienne to:\n",
    "* X1 - Przeciętne wynagrodzenie [pln]\n",
    "* X2 - Współczynnik scholaryzacji szkół podstawowych\n",
    "* X3 - Bezrobocie rejestrowane\n",
    "* X4 - Ilość samochodów osobowych na 1000 mieszkańców\n",
    "* X5 - Apteki na 1000 mieszkańców\n",
    "* X6 - Ilość podmiotów wpisanych do REGON na 10000 mieszkańców\n",
    "* X7 – Osoby fizyczne prowadzące działalność gosp. na 1000 mieszkańców\n",
    "* X8 - Wykrywalność przestępstw [%]\n",
    "* X9 – Przestępstwa na 1000 mieszkańców\n",
    "* X10 – Przychodnie na 10000 ludności\n",
    "* X11 - Rodziny zastępcze na 10000 ludności\n",
    "\n",
    "Żródłem danych jest Bank Danych Lokalnych (GUS)> Wszystkie dane dotyczą roku 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twoim celem jest:\n",
    "* Wstępna analiza danych - statystyki opisowe, rozkłady empiryczne, wykresy zależności, macierz korelacji - wraz z interpretacją\n",
    "* Analiza głównych składowych - ile składowych głównych powinno reprezentować ten zbiór? Jak zinterpretujesz macierz ładunków? Na początku spróbuj dokonać analizy głównych składowych bez standaryzacji zbioru danych\n",
    "\n",
    "* Wizualizacja zbioru za pomocą trzech głównych składowych. Czy widać jakieś powiaty odstające?\n",
    "* Analiza skupień - za pomocą wybranej metody z zajęć nr 1. dokonaj klastrowania na grupy podobnych sobie powiatów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T17:26:18.883186Z",
     "start_time": "2019-04-03T17:26:18.875193Z"
    }
   },
   "outputs": [],
   "source": [
    "powiaty = pd.read_csv('powiaty.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lektura do poduszki:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Artykuł naukowy wprowadzający t-SNE: http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf\n",
    " - t-SNE trochę przyjaźniejszym językiem: http://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/\n",
    " - Rozdział *Principal Components, Curves and Surfaces* z nieocenionego *Elements of Statistical Learning* https://web.stanford.edu/~hastie/Papers/ESLII.pdf\n",
    " - PCA - z matematycznego na nasze https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
